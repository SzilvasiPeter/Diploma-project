{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "student_df = pd.read_csv('../../datasets/student_mat_processed01.csv')\n",
    "\n",
    "train_dataset = student_df.sample(frac=0.8, random_state=0)\n",
    "test_dataset = student_df.drop(train_dataset.index)\n",
    "\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_G1_targets = train_features.pop('G1')\n",
    "train_G2_targets = train_features.pop('G2')\n",
    "train_G3_targets = train_features.pop('G3')\n",
    "\n",
    "test_G1_targets = test_features.pop('G1')\n",
    "test_G2_targets = test_features.pop('G2')\n",
    "test_G3_targets = test_features.pop('G3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizer Layer\n",
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(np.array(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture.\n",
    "def build_and_compile_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(45)),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(16, activation='relu'),\n",
    "        keras.layers.Dense(8, activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Train the model\n",
    "    model.compile(loss='mean_absolute_error', metrics=[tf.keras.metrics.MeanAbsoluteError()],\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 32)                1472      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,145\n",
      "Trainable params: 2,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc_model = build_and_compile_model()\n",
    "fc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 9.5633 - mean_absolute_error: 9.5633 - val_loss: 10.0867 - val_mean_absolute_error: 10.0867\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.7064 - mean_absolute_error: 8.7064 - val_loss: 9.3412 - val_mean_absolute_error: 9.3412\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.0079 - mean_absolute_error: 8.0079 - val_loss: 8.5286 - val_mean_absolute_error: 8.5286\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.2579 - mean_absolute_error: 7.2579 - val_loss: 7.5121 - val_mean_absolute_error: 7.5121\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.4111 - mean_absolute_error: 6.4111 - val_loss: 6.3569 - val_mean_absolute_error: 6.3569\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.3992 - mean_absolute_error: 5.3992 - val_loss: 4.8502 - val_mean_absolute_error: 4.8502\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.3219 - mean_absolute_error: 4.3219 - val_loss: 3.8308 - val_mean_absolute_error: 3.8308\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1188 - mean_absolute_error: 4.1188 - val_loss: 3.6245 - val_mean_absolute_error: 3.6245\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.0032 - mean_absolute_error: 4.0032 - val_loss: 3.6622 - val_mean_absolute_error: 3.6622\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8767 - mean_absolute_error: 3.8767 - val_loss: 3.7360 - val_mean_absolute_error: 3.7360\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.8041 - mean_absolute_error: 3.8041 - val_loss: 3.5692 - val_mean_absolute_error: 3.5692\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.7093 - mean_absolute_error: 3.7093 - val_loss: 3.4528 - val_mean_absolute_error: 3.4528\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.6591 - mean_absolute_error: 3.6591 - val_loss: 3.4510 - val_mean_absolute_error: 3.4510\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.5770 - mean_absolute_error: 3.5770 - val_loss: 3.3580 - val_mean_absolute_error: 3.3580\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5285 - mean_absolute_error: 3.5285 - val_loss: 3.3464 - val_mean_absolute_error: 3.3464\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4762 - mean_absolute_error: 3.4762 - val_loss: 3.4107 - val_mean_absolute_error: 3.4107\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4364 - mean_absolute_error: 3.4364 - val_loss: 3.4114 - val_mean_absolute_error: 3.4114\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4196 - mean_absolute_error: 3.4196 - val_loss: 3.3740 - val_mean_absolute_error: 3.3740\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4071 - mean_absolute_error: 3.4071 - val_loss: 3.3820 - val_mean_absolute_error: 3.3820\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3966 - mean_absolute_error: 3.3966 - val_loss: 3.4108 - val_mean_absolute_error: 3.4108\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3547 - mean_absolute_error: 3.3547 - val_loss: 3.2777 - val_mean_absolute_error: 3.2777\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3652 - mean_absolute_error: 3.3652 - val_loss: 3.4552 - val_mean_absolute_error: 3.4552\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3374 - mean_absolute_error: 3.3374 - val_loss: 3.3654 - val_mean_absolute_error: 3.3654\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3183 - mean_absolute_error: 3.3183 - val_loss: 3.3861 - val_mean_absolute_error: 3.3861\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2819 - mean_absolute_error: 3.2819 - val_loss: 3.2938 - val_mean_absolute_error: 3.2938\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2880 - mean_absolute_error: 3.2880 - val_loss: 3.3272 - val_mean_absolute_error: 3.3272\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2768 - mean_absolute_error: 3.2768 - val_loss: 3.4143 - val_mean_absolute_error: 3.4143\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2437 - mean_absolute_error: 3.2437 - val_loss: 3.2710 - val_mean_absolute_error: 3.2710\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2420 - mean_absolute_error: 3.2420 - val_loss: 3.3396 - val_mean_absolute_error: 3.3396\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2055 - mean_absolute_error: 3.2055 - val_loss: 3.3688 - val_mean_absolute_error: 3.3688\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2331 - mean_absolute_error: 3.2331 - val_loss: 3.3870 - val_mean_absolute_error: 3.3870\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1639 - mean_absolute_error: 3.1639 - val_loss: 3.2042 - val_mean_absolute_error: 3.2042\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1577 - mean_absolute_error: 3.1577 - val_loss: 3.3134 - val_mean_absolute_error: 3.3134\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1463 - mean_absolute_error: 3.1463 - val_loss: 3.3916 - val_mean_absolute_error: 3.3916\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1236 - mean_absolute_error: 3.1236 - val_loss: 3.1929 - val_mean_absolute_error: 3.1929\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1021 - mean_absolute_error: 3.1021 - val_loss: 3.3242 - val_mean_absolute_error: 3.3242\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0966 - mean_absolute_error: 3.0966 - val_loss: 3.2520 - val_mean_absolute_error: 3.2520\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.0754 - mean_absolute_error: 3.0754 - val_loss: 3.2222 - val_mean_absolute_error: 3.2222\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.0613 - mean_absolute_error: 3.0613 - val_loss: 3.3616 - val_mean_absolute_error: 3.3616\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0716 - mean_absolute_error: 3.0716 - val_loss: 3.3048 - val_mean_absolute_error: 3.3048\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1321 - mean_absolute_error: 3.1321 - val_loss: 3.1241 - val_mean_absolute_error: 3.1241\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.0241 - mean_absolute_error: 3.0241 - val_loss: 3.4817 - val_mean_absolute_error: 3.4817\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.0232 - mean_absolute_error: 3.0232 - val_loss: 3.2096 - val_mean_absolute_error: 3.2096\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.9916 - mean_absolute_error: 2.9916 - val_loss: 3.2233 - val_mean_absolute_error: 3.2233\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.9919 - mean_absolute_error: 2.9919 - val_loss: 3.3105 - val_mean_absolute_error: 3.3105\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.9728 - mean_absolute_error: 2.9728 - val_loss: 3.0382 - val_mean_absolute_error: 3.0382\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.9555 - mean_absolute_error: 2.9555 - val_loss: 3.2638 - val_mean_absolute_error: 3.2638\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.9391 - mean_absolute_error: 2.9391 - val_loss: 3.2581 - val_mean_absolute_error: 3.2581\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.9742 - mean_absolute_error: 2.9742 - val_loss: 3.0874 - val_mean_absolute_error: 3.0874\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.9202 - mean_absolute_error: 2.9202 - val_loss: 3.3328 - val_mean_absolute_error: 3.3328\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 2.8988 - mean_absolute_error: 2.8988 - val_loss: 3.1594 - val_mean_absolute_error: 3.1594\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.8763 - mean_absolute_error: 2.8763 - val_loss: 3.2833 - val_mean_absolute_error: 3.2833\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.8545 - mean_absolute_error: 2.8545 - val_loss: 3.2033 - val_mean_absolute_error: 3.2033\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.8842 - mean_absolute_error: 2.8842 - val_loss: 3.1974 - val_mean_absolute_error: 3.1974\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.8315 - mean_absolute_error: 2.8315 - val_loss: 3.2912 - val_mean_absolute_error: 3.2912\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.9192 - mean_absolute_error: 2.9192 - val_loss: 3.0420 - val_mean_absolute_error: 3.0420\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.8537 - mean_absolute_error: 2.8537 - val_loss: 3.3145 - val_mean_absolute_error: 3.3145\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.8165 - mean_absolute_error: 2.8165 - val_loss: 3.1100 - val_mean_absolute_error: 3.1100\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.7886 - mean_absolute_error: 2.7886 - val_loss: 3.1537 - val_mean_absolute_error: 3.1537\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.7565 - mean_absolute_error: 2.7565 - val_loss: 3.1673 - val_mean_absolute_error: 3.1673\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.7284 - mean_absolute_error: 2.7284 - val_loss: 3.1744 - val_mean_absolute_error: 3.1744\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.7246 - mean_absolute_error: 2.7246 - val_loss: 3.1287 - val_mean_absolute_error: 3.1287\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.7023 - mean_absolute_error: 2.7023 - val_loss: 3.2789 - val_mean_absolute_error: 3.2789\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.6894 - mean_absolute_error: 2.6894 - val_loss: 3.1030 - val_mean_absolute_error: 3.1030\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.6860 - mean_absolute_error: 2.6860 - val_loss: 3.1737 - val_mean_absolute_error: 3.1737\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.6948 - mean_absolute_error: 2.6948 - val_loss: 3.1242 - val_mean_absolute_error: 3.1242\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.6540 - mean_absolute_error: 2.6540 - val_loss: 3.2722 - val_mean_absolute_error: 3.2722\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.6320 - mean_absolute_error: 2.6320 - val_loss: 3.1616 - val_mean_absolute_error: 3.1616\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.6242 - mean_absolute_error: 2.6242 - val_loss: 3.1542 - val_mean_absolute_error: 3.1542\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.6120 - mean_absolute_error: 2.6120 - val_loss: 3.2539 - val_mean_absolute_error: 3.2539\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.6266 - mean_absolute_error: 2.6266 - val_loss: 3.2042 - val_mean_absolute_error: 3.2042\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.5669 - mean_absolute_error: 2.5669 - val_loss: 3.1069 - val_mean_absolute_error: 3.1069\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.5885 - mean_absolute_error: 2.5885 - val_loss: 3.2271 - val_mean_absolute_error: 3.2271\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.5612 - mean_absolute_error: 2.5612 - val_loss: 3.1872 - val_mean_absolute_error: 3.1872\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.5477 - mean_absolute_error: 2.5477 - val_loss: 3.1107 - val_mean_absolute_error: 3.1107\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.5519 - mean_absolute_error: 2.5519 - val_loss: 3.1264 - val_mean_absolute_error: 3.1264\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.5064 - mean_absolute_error: 2.5064 - val_loss: 3.1162 - val_mean_absolute_error: 3.1162\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.5297 - mean_absolute_error: 2.5297 - val_loss: 3.2452 - val_mean_absolute_error: 3.2452\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.4967 - mean_absolute_error: 2.4967 - val_loss: 3.0624 - val_mean_absolute_error: 3.0624\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.4698 - mean_absolute_error: 2.4698 - val_loss: 3.2603 - val_mean_absolute_error: 3.2603\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.4739 - mean_absolute_error: 2.4739 - val_loss: 3.1176 - val_mean_absolute_error: 3.1176\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.4463 - mean_absolute_error: 2.4463 - val_loss: 3.0774 - val_mean_absolute_error: 3.0774\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.4414 - mean_absolute_error: 2.4414 - val_loss: 3.1390 - val_mean_absolute_error: 3.1390\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.4329 - mean_absolute_error: 2.4329 - val_loss: 3.1291 - val_mean_absolute_error: 3.1291\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.4564 - mean_absolute_error: 2.4564 - val_loss: 3.0450 - val_mean_absolute_error: 3.0450\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.4329 - mean_absolute_error: 2.4329 - val_loss: 3.2990 - val_mean_absolute_error: 3.2990\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.3751 - mean_absolute_error: 2.3751 - val_loss: 3.0629 - val_mean_absolute_error: 3.0629\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.3703 - mean_absolute_error: 2.3703 - val_loss: 3.1320 - val_mean_absolute_error: 3.1320\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.3396 - mean_absolute_error: 2.3396 - val_loss: 3.1010 - val_mean_absolute_error: 3.1010\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.3374 - mean_absolute_error: 2.3374 - val_loss: 3.2404 - val_mean_absolute_error: 3.2404\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.3576 - mean_absolute_error: 2.3576 - val_loss: 3.1163 - val_mean_absolute_error: 3.1163\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.3269 - mean_absolute_error: 2.3269 - val_loss: 3.0520 - val_mean_absolute_error: 3.0520\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.3676 - mean_absolute_error: 2.3676 - val_loss: 3.2589 - val_mean_absolute_error: 3.2589\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.2817 - mean_absolute_error: 2.2817 - val_loss: 3.0771 - val_mean_absolute_error: 3.0771\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.2833 - mean_absolute_error: 2.2833 - val_loss: 3.1848 - val_mean_absolute_error: 3.1848\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.2669 - mean_absolute_error: 2.2669 - val_loss: 3.1113 - val_mean_absolute_error: 3.1113\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.2436 - mean_absolute_error: 2.2436 - val_loss: 3.1592 - val_mean_absolute_error: 3.1592\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.2375 - mean_absolute_error: 2.2375 - val_loss: 3.1279 - val_mean_absolute_error: 3.1279\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.2277 - mean_absolute_error: 2.2277 - val_loss: 3.1488 - val_mean_absolute_error: 3.1488\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.2268 - mean_absolute_error: 2.2268 - val_loss: 3.0669 - val_mean_absolute_error: 3.0669\n"
     ]
    }
   ],
   "source": [
    "history = fc_model.fit(\n",
    "    train_features, train_G3_targets,\n",
    "    validation_split=0.2,\n",
    "    verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline mean absolute error: 3.327263593673706\n",
      "Saved baseline model to: C:\\Users\\z0042fkb\\AppData\\Local\\Temp\\tmpti92je5d.h5\n"
     ]
    }
   ],
   "source": [
    "test_results = {}\n",
    "_, test_results['fc_model'] = fc_model.evaluate(test_features, test_G3_targets, verbose=0)\n",
    "\n",
    "print('Baseline mean absolute error:', test_results['fc_model'])\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(fc_model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 32\n",
    "epochs = 8\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set.\n",
    "\n",
    "num_features = train_features.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_features / batch_size).astype(np.int32) * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "    'pruning_schedule':\n",
    "    tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                         final_sparsity=0.80,\n",
    "                                         begin_step=0,\n",
    "                                         end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(fc_model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_dense_4  (None, 32)                2914      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_5  (None, 16)                1042      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_6  (None, 8)                 266       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_7  (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 4,241\n",
      "Trainable params: 2,145\n",
      "Non-trainable params: 2,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='mean_absolute_error',\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "2/9 [=====>........................] - ETA: 19s - loss: 6.9465 - mean_absolute_error: 6.9465WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_begin` time: 0.0298s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_begin` time: 0.0298s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 5.4356s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 5.4356s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 675ms/step - loss: 6.4324 - mean_absolute_error: 6.4324 - val_loss: 6.2029 - val_mean_absolute_error: 6.2029\n",
      "Epoch 2/8\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 4.8711 - mean_absolute_error: 4.8711 - val_loss: 4.7083 - val_mean_absolute_error: 4.7083\n",
      "Epoch 3/8\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3.6748 - mean_absolute_error: 3.6748 - val_loss: 3.7654 - val_mean_absolute_error: 3.7654\n",
      "Epoch 4/8\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3.2219 - mean_absolute_error: 3.2219 - val_loss: 3.3748 - val_mean_absolute_error: 3.3748\n",
      "Epoch 5/8\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3.0859 - mean_absolute_error: 3.0859 - val_loss: 3.2134 - val_mean_absolute_error: 3.2134\n",
      "Epoch 6/8\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3.0631 - mean_absolute_error: 3.0631 - val_loss: 3.1850 - val_mean_absolute_error: 3.1850\n",
      "Epoch 7/8\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3.0374 - mean_absolute_error: 3.0374 - val_loss: 3.1793 - val_mean_absolute_error: 3.1793\n",
      "Epoch 8/8\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 3.0039 - mean_absolute_error: 3.0039 - val_loss: 3.1874 - val_mean_absolute_error: 3.1874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x220064be4e0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and evaluate the model against baseline\n",
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_features, train_G3_targets,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2374 - mean_absolute_error: 3.2374\n",
      "Baseline mean absolute error: 3.30635404586792\n",
      "Pruned mean absolute error: 3.2373874187469482\n"
     ]
    }
   ],
   "source": [
    "_, test_results['pruned_model'] = model_for_pruning.evaluate(\n",
    "   test_features, test_G3_targets, verbose=1)\n",
    "\n",
    "print('Baseline mean absolute error:', test_results['fc_model']) \n",
    "print('Pruned mean absolute error:', test_results['pruned_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: C:\\Users\\z0042fkb\\AppData\\Local\\Temp\\tmpmzejx93k.h5\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export,\n",
    "                           pruned_keras_file,\n",
    "                           include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\z0042fkb\\AppData\\Local\\Temp\\tmpkahc1xcp\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\z0042fkb\\AppData\\Local\\Temp\\tmpkahc1xcp\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: C:\\Users\\z0042fkb\\AppData\\Local\\Temp\\tmp1dqzg5j3.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 9872.00 bytes\n",
      "Size of gzipped pruned Keras model: 6805.00 bytes\n",
      "Size of gzipped pruned TFlite model: 5982.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 0).\n",
       "Contents of stderr:\n",
       "2021-04-27 17:50:53.881608: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n",
       "2021-04-27 17:50:53.890311: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
       "Logged out of uploader."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!pip install -U tensorboard\n",
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir={logdir}\n",
    "#print(logdir)\n",
    "#%tensorboard dev upload --logdir 'C:\\\\Users\\\\z0042fkb\\\\AppData\\\\Local\\\\Temp\\\\tmppg6etlnp'\n",
    "#%tensorboard dev auth revoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
