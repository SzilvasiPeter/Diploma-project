{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "student_df = pd.read_csv('../../datasets/student_mat_processed01.csv')\n",
    "\n",
    "train_dataset = student_df.sample(frac=0.8, random_state=0)\n",
    "test_dataset = student_df.drop(train_dataset.index)\n",
    "\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_G1_targets = train_features.pop('G1')\n",
    "train_G2_targets = train_features.pop('G2')\n",
    "train_G3_targets = train_features.pop('G3')\n",
    "\n",
    "test_G1_targets = test_features.pop('G1')\n",
    "test_G2_targets = test_features.pop('G2')\n",
    "test_G3_targets = test_features.pop('G3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizer Layer\n",
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(np.array(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture.\n",
    "def build_and_compile_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(45)),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(16, activation='relu'),\n",
    "        keras.layers.Dense(8, activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Train the model\n",
    "    model.compile(loss='mean_absolute_error', metrics=[tf.keras.metrics.MeanAbsoluteError()],\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                1472      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,145\n",
      "Trainable params: 2,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc_model = build_and_compile_model()\n",
    "fc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 5.2063 - mean_absolute_error: 5.2063 - val_loss: 4.4646 - val_mean_absolute_error: 4.4646\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 4.2377 - mean_absolute_error: 4.2377 - val_loss: 3.7437 - val_mean_absolute_error: 3.7437\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.0881 - mean_absolute_error: 4.0881 - val_loss: 3.6093 - val_mean_absolute_error: 3.6093\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.8253 - mean_absolute_error: 3.8253 - val_loss: 3.9452 - val_mean_absolute_error: 3.9452\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6952 - mean_absolute_error: 3.6952 - val_loss: 3.6120 - val_mean_absolute_error: 3.6120\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.5974 - mean_absolute_error: 3.5974 - val_loss: 3.3959 - val_mean_absolute_error: 3.3959\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.4867 - mean_absolute_error: 3.4867 - val_loss: 3.4774 - val_mean_absolute_error: 3.4774\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.4995 - mean_absolute_error: 3.4995 - val_loss: 3.5106 - val_mean_absolute_error: 3.5106\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3.4428 - mean_absolute_error: 3.4428 - val_loss: 3.3309 - val_mean_absolute_error: 3.3309\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.4301 - mean_absolute_error: 3.4301 - val_loss: 3.4592 - val_mean_absolute_error: 3.4592\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.3813 - mean_absolute_error: 3.3813 - val_loss: 3.3804 - val_mean_absolute_error: 3.3804\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3548 - mean_absolute_error: 3.3548 - val_loss: 3.3979 - val_mean_absolute_error: 3.3979\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.3381 - mean_absolute_error: 3.3381 - val_loss: 3.3991 - val_mean_absolute_error: 3.3991\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3008 - mean_absolute_error: 3.3008 - val_loss: 3.4058 - val_mean_absolute_error: 3.4058\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2877 - mean_absolute_error: 3.2877 - val_loss: 3.3362 - val_mean_absolute_error: 3.3362\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2701 - mean_absolute_error: 3.2701 - val_loss: 3.3879 - val_mean_absolute_error: 3.3879\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2342 - mean_absolute_error: 3.2342 - val_loss: 3.4116 - val_mean_absolute_error: 3.4116\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2376 - mean_absolute_error: 3.2376 - val_loss: 3.3240 - val_mean_absolute_error: 3.3240\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2252 - mean_absolute_error: 3.2252 - val_loss: 3.2825 - val_mean_absolute_error: 3.2825\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1841 - mean_absolute_error: 3.1841 - val_loss: 3.3672 - val_mean_absolute_error: 3.3672\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1390 - mean_absolute_error: 3.1390 - val_loss: 3.2696 - val_mean_absolute_error: 3.2696\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1192 - mean_absolute_error: 3.1192 - val_loss: 3.3840 - val_mean_absolute_error: 3.3840\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1088 - mean_absolute_error: 3.1088 - val_loss: 3.3030 - val_mean_absolute_error: 3.3030\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0991 - mean_absolute_error: 3.0991 - val_loss: 3.3175 - val_mean_absolute_error: 3.3175\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.0617 - mean_absolute_error: 3.0617 - val_loss: 3.3555 - val_mean_absolute_error: 3.3555\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.0405 - mean_absolute_error: 3.0405 - val_loss: 3.2983 - val_mean_absolute_error: 3.2983\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.0293 - mean_absolute_error: 3.0293 - val_loss: 3.2490 - val_mean_absolute_error: 3.2490\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.0237 - mean_absolute_error: 3.0237 - val_loss: 3.2885 - val_mean_absolute_error: 3.2885\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.0702 - mean_absolute_error: 3.0702 - val_loss: 3.2443 - val_mean_absolute_error: 3.2443\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.9914 - mean_absolute_error: 2.9914 - val_loss: 3.1620 - val_mean_absolute_error: 3.1620\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.9590 - mean_absolute_error: 2.9590 - val_loss: 3.3502 - val_mean_absolute_error: 3.3502\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.9404 - mean_absolute_error: 2.9404 - val_loss: 3.2581 - val_mean_absolute_error: 3.2581\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.9230 - mean_absolute_error: 2.9230 - val_loss: 3.2331 - val_mean_absolute_error: 3.2331\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.8856 - mean_absolute_error: 2.8856 - val_loss: 3.2723 - val_mean_absolute_error: 3.2723\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.8651 - mean_absolute_error: 2.8651 - val_loss: 3.1795 - val_mean_absolute_error: 3.1795\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.8459 - mean_absolute_error: 2.8459 - val_loss: 3.2659 - val_mean_absolute_error: 3.2659\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.8172 - mean_absolute_error: 2.8172 - val_loss: 3.1154 - val_mean_absolute_error: 3.1154\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.8425 - mean_absolute_error: 2.8425 - val_loss: 3.3281 - val_mean_absolute_error: 3.3281\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.8070 - mean_absolute_error: 2.8070 - val_loss: 3.1812 - val_mean_absolute_error: 3.1812\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.7714 - mean_absolute_error: 2.7714 - val_loss: 3.1867 - val_mean_absolute_error: 3.1867\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.7587 - mean_absolute_error: 2.7587 - val_loss: 3.0924 - val_mean_absolute_error: 3.0924\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.7809 - mean_absolute_error: 2.7809 - val_loss: 3.3447 - val_mean_absolute_error: 3.3447\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.7446 - mean_absolute_error: 2.7446 - val_loss: 3.1761 - val_mean_absolute_error: 3.1761\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.7292 - mean_absolute_error: 2.7292 - val_loss: 3.0968 - val_mean_absolute_error: 3.0968\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.6792 - mean_absolute_error: 2.6792 - val_loss: 3.3679 - val_mean_absolute_error: 3.3679\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.7197 - mean_absolute_error: 2.7197 - val_loss: 3.0901 - val_mean_absolute_error: 3.0901\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.6715 - mean_absolute_error: 2.6715 - val_loss: 3.2634 - val_mean_absolute_error: 3.2634\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.6714 - mean_absolute_error: 2.6714 - val_loss: 3.0989 - val_mean_absolute_error: 3.0989\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.6298 - mean_absolute_error: 2.6298 - val_loss: 3.2111 - val_mean_absolute_error: 3.2111\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.6023 - mean_absolute_error: 2.6023 - val_loss: 3.2470 - val_mean_absolute_error: 3.2470\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 2.6157 - mean_absolute_error: 2.6157 - val_loss: 3.1480 - val_mean_absolute_error: 3.1480\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.5912 - mean_absolute_error: 2.5912 - val_loss: 3.1393 - val_mean_absolute_error: 3.1393\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.5542 - mean_absolute_error: 2.5542 - val_loss: 3.1863 - val_mean_absolute_error: 3.1863\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.5922 - mean_absolute_error: 2.5922 - val_loss: 3.2647 - val_mean_absolute_error: 3.2647\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.6083 - mean_absolute_error: 2.6083 - val_loss: 3.0117 - val_mean_absolute_error: 3.0117\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.5237 - mean_absolute_error: 2.5237 - val_loss: 3.3117 - val_mean_absolute_error: 3.3117\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.5165 - mean_absolute_error: 2.5165 - val_loss: 3.1588 - val_mean_absolute_error: 3.1588\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.4690 - mean_absolute_error: 2.4690 - val_loss: 3.1126 - val_mean_absolute_error: 3.1126\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.4475 - mean_absolute_error: 2.4475 - val_loss: 3.2093 - val_mean_absolute_error: 3.2093\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.4321 - mean_absolute_error: 2.4321 - val_loss: 3.0906 - val_mean_absolute_error: 3.0906\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.4207 - mean_absolute_error: 2.4207 - val_loss: 3.2653 - val_mean_absolute_error: 3.2653\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.4508 - mean_absolute_error: 2.4508 - val_loss: 3.0795 - val_mean_absolute_error: 3.0795\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.5344 - mean_absolute_error: 2.5344 - val_loss: 2.9975 - val_mean_absolute_error: 2.9975\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.4677 - mean_absolute_error: 2.4677 - val_loss: 3.2769 - val_mean_absolute_error: 3.2769\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.3649 - mean_absolute_error: 2.3649 - val_loss: 3.0453 - val_mean_absolute_error: 3.0453\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.3536 - mean_absolute_error: 2.3536 - val_loss: 3.1546 - val_mean_absolute_error: 3.1546\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.3441 - mean_absolute_error: 2.3441 - val_loss: 3.1224 - val_mean_absolute_error: 3.1224\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.3583 - mean_absolute_error: 2.3583 - val_loss: 3.0505 - val_mean_absolute_error: 3.0505\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.3164 - mean_absolute_error: 2.3164 - val_loss: 3.2168 - val_mean_absolute_error: 3.2168\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.3570 - mean_absolute_error: 2.3570 - val_loss: 3.1748 - val_mean_absolute_error: 3.1748\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.3171 - mean_absolute_error: 2.3171 - val_loss: 3.1315 - val_mean_absolute_error: 3.1315\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.3203 - mean_absolute_error: 2.3203 - val_loss: 2.9689 - val_mean_absolute_error: 2.9689\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.2534 - mean_absolute_error: 2.2534 - val_loss: 3.2672 - val_mean_absolute_error: 3.2672\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.2925 - mean_absolute_error: 2.2925 - val_loss: 3.0513 - val_mean_absolute_error: 3.0513\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.2966 - mean_absolute_error: 2.2966 - val_loss: 3.0536 - val_mean_absolute_error: 3.0536\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.3302 - mean_absolute_error: 2.3302 - val_loss: 3.2728 - val_mean_absolute_error: 3.2728\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.2824 - mean_absolute_error: 2.2824 - val_loss: 2.9960 - val_mean_absolute_error: 2.9960\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.2259 - mean_absolute_error: 2.2259 - val_loss: 3.1679 - val_mean_absolute_error: 3.1679\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.2126 - mean_absolute_error: 2.2126 - val_loss: 3.0491 - val_mean_absolute_error: 3.0491\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.2574 - mean_absolute_error: 2.2574 - val_loss: 3.0297 - val_mean_absolute_error: 3.0297\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.2551 - mean_absolute_error: 2.2551 - val_loss: 3.2598 - val_mean_absolute_error: 3.2598\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.2480 - mean_absolute_error: 2.2480 - val_loss: 3.0445 - val_mean_absolute_error: 3.0445\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.1789 - mean_absolute_error: 2.1789 - val_loss: 3.0901 - val_mean_absolute_error: 3.0901\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.1442 - mean_absolute_error: 2.1442 - val_loss: 3.0473 - val_mean_absolute_error: 3.0473\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.1482 - mean_absolute_error: 2.1482 - val_loss: 3.0167 - val_mean_absolute_error: 3.0167\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.1901 - mean_absolute_error: 2.1901 - val_loss: 3.0178 - val_mean_absolute_error: 3.0178\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.1638 - mean_absolute_error: 2.1638 - val_loss: 3.0610 - val_mean_absolute_error: 3.0610\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.0992 - mean_absolute_error: 2.0992 - val_loss: 3.1603 - val_mean_absolute_error: 3.1603\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.1094 - mean_absolute_error: 2.1094 - val_loss: 3.1122 - val_mean_absolute_error: 3.1122\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.0778 - mean_absolute_error: 2.0778 - val_loss: 3.0909 - val_mean_absolute_error: 3.0909\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.0437 - mean_absolute_error: 2.0437 - val_loss: 3.1189 - val_mean_absolute_error: 3.1189\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.0419 - mean_absolute_error: 2.0419 - val_loss: 3.0402 - val_mean_absolute_error: 3.0402\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.0326 - mean_absolute_error: 2.0326 - val_loss: 3.0547 - val_mean_absolute_error: 3.0547\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.0054 - mean_absolute_error: 2.0054 - val_loss: 3.1338 - val_mean_absolute_error: 3.1338\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.0481 - mean_absolute_error: 2.0481 - val_loss: 3.2396 - val_mean_absolute_error: 3.2396\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.1186 - mean_absolute_error: 2.1186 - val_loss: 3.0253 - val_mean_absolute_error: 3.0253\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.0690 - mean_absolute_error: 2.0690 - val_loss: 3.0134 - val_mean_absolute_error: 3.0134\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.0498 - mean_absolute_error: 2.0498 - val_loss: 3.0290 - val_mean_absolute_error: 3.0290\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.9807 - mean_absolute_error: 1.9807 - val_loss: 3.0775 - val_mean_absolute_error: 3.0775\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.9720 - mean_absolute_error: 1.9720 - val_loss: 3.0402 - val_mean_absolute_error: 3.0402\n"
     ]
    }
   ],
   "source": [
    "history = fc_model.fit(\n",
    "    train_features, train_G3_targets,\n",
    "    validation_split=0.2,\n",
    "    verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline mean absolute error: 3.503624200820923\n",
      "Saved baseline model to: C:\\Users\\z0042fkb\\AppData\\Local\\Temp\\tmpwj541jgh.h5\n"
     ]
    }
   ],
   "source": [
    "test_results = {}\n",
    "_, test_results['fc_model'] = fc_model.evaluate(test_features, test_G3_targets, verbose=0)\n",
    "\n",
    "print('Baseline mean absolute error:', test_results['fc_model'])\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(fc_model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set.\n",
    "\n",
    "num_features = train_features.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_features / batch_size).astype(np.int32) * epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\z0042fkb\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_wrapper.py:200: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "    'pruning_schedule':\n",
    "    tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                         final_sparsity=0.80,\n",
    "                                         begin_step=0,\n",
    "                                         end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(fc_model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_dense (P (None, 32)                2914      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_1  (None, 16)                1042      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_2  (None, 8)                 266       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_3  (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 4,241\n",
      "Trainable params: 2,145\n",
      "Non-trainable params: 2,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='mean_absolute_error',\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2/9 [=====>........................] - ETA: 2s - loss: 4.5091 - mean_absolute_error: 4.5091WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0023s vs `on_train_batch_begin` time: 0.0094s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0023s vs `on_train_batch_end` time: 0.7306s). Check your callbacks.\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 4.0242 - mean_absolute_error: 4.0242 - val_loss: 4.0191 - val_mean_absolute_error: 4.0191\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 3.4255 - mean_absolute_error: 3.4255 - val_loss: 3.4465 - val_mean_absolute_error: 3.4465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a37f4eb4a8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and evaluate the model against baseline\n",
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_features, train_G3_targets,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step - loss: 3.6341 - mean_absolute_error: 3.6341\n",
      "Baseline mean absolute error: 3.503624200820923\n",
      "Pruned mean absolute error: 3.6340973377227783\n"
     ]
    }
   ],
   "source": [
    "_, test_results['pruned_model'] = model_for_pruning.evaluate(\n",
    "   test_features, test_G3_targets, verbose=1)\n",
    "\n",
    "print('Baseline mean absolute error:', test_results['fc_model']) \n",
    "print('Pruned mean absolute error:', test_results['pruned_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: C:\\Users\\z0042fkb\\AppData\\Local\\Temp\\tmpjlwj9uj3.h5\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export,\n",
    "                           pruned_keras_file,\n",
    "                           include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\z0042fkb\\AppData\\Local\\Temp\\tmps9zzw175\\assets\n",
      "Saved pruned TFLite model to: C:\\Users\\z0042fkb\\AppData\\Local\\Temp\\tmpr_73aunn.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 9916.00 bytes\n",
      "Size of gzipped pruned Keras model: 6842.00 bytes\n",
      "Size of gzipped pruned TFlite model: 5971.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 0).\n",
       "Contents of stderr:\n",
       "2021-04-27 17:50:53.881608: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\n",
       "2021-04-27 17:50:53.890311: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
       "Logged out of uploader."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!pip install -U tensorboard\n",
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir={logdir}\n",
    "#print(logdir)\n",
    "#%tensorboard dev upload --logdir 'C:\\\\Users\\\\z0042fkb\\\\AppData\\\\Local\\\\Temp\\\\tmppg6etlnp'\n",
    "#%tensorboard dev auth revoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
