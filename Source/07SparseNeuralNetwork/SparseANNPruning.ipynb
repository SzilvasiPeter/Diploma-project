{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "student_df = pd.read_csv('../../datasets/student_mat_processed01.csv')\n",
    "\n",
    "train_dataset = student_df.sample(frac=0.8, random_state=0)\n",
    "test_dataset = student_df.drop(train_dataset.index)\n",
    "\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_G1_targets = train_features.pop('G1')\n",
    "train_G2_targets = train_features.pop('G2')\n",
    "train_G3_targets = train_features.pop('G3')\n",
    "\n",
    "test_G1_targets = test_features.pop('G1')\n",
    "test_G2_targets = test_features.pop('G2')\n",
    "test_G3_targets = test_features.pop('G3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizer Layer\n",
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(np.array(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture.\n",
    "def build_and_compile_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(45)),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(16, activation='relu'),\n",
    "        keras.layers.Dense(8, activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Train the model\n",
    "    model.compile(loss='mean_absolute_error', metrics=[tf.keras.metrics.MeanAbsoluteError()],\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 32)                1472      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,145\n",
      "Trainable params: 2,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc_model = build_and_compile_model()\n",
    "fc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 9.2220 - mean_absolute_error: 9.2220 - val_loss: 9.3482 - val_mean_absolute_error: 9.3482\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.7513 - mean_absolute_error: 7.7513 - val_loss: 7.5890 - val_mean_absolute_error: 7.5890\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.2526 - mean_absolute_error: 6.2526 - val_loss: 5.9949 - val_mean_absolute_error: 5.9949\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.1715 - mean_absolute_error: 5.1715 - val_loss: 4.7786 - val_mean_absolute_error: 4.7786\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4.4839 - mean_absolute_error: 4.4839 - val_loss: 3.9029 - val_mean_absolute_error: 3.9029\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 4.0923 - mean_absolute_error: 4.0923 - val_loss: 3.5588 - val_mean_absolute_error: 3.5588\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 3.9175 - mean_absolute_error: 3.9175 - val_loss: 3.3995 - val_mean_absolute_error: 3.3995\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.7384 - mean_absolute_error: 3.7384 - val_loss: 3.5376 - val_mean_absolute_error: 3.5376\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.6659 - mean_absolute_error: 3.6659 - val_loss: 3.5157 - val_mean_absolute_error: 3.5157\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.6283 - mean_absolute_error: 3.6283 - val_loss: 3.3770 - val_mean_absolute_error: 3.3770\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.5831 - mean_absolute_error: 3.5831 - val_loss: 3.3673 - val_mean_absolute_error: 3.3673\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.5562 - mean_absolute_error: 3.5562 - val_loss: 3.3581 - val_mean_absolute_error: 3.3581\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 3.5336 - mean_absolute_error: 3.5336 - val_loss: 3.2808 - val_mean_absolute_error: 3.2808\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.5126 - mean_absolute_error: 3.5126 - val_loss: 3.3592 - val_mean_absolute_error: 3.3592\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.4858 - mean_absolute_error: 3.4858 - val_loss: 3.3254 - val_mean_absolute_error: 3.3254\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4635 - mean_absolute_error: 3.4635 - val_loss: 3.3146 - val_mean_absolute_error: 3.3146\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4427 - mean_absolute_error: 3.4427 - val_loss: 3.3572 - val_mean_absolute_error: 3.3572\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4243 - mean_absolute_error: 3.4243 - val_loss: 3.2922 - val_mean_absolute_error: 3.2922\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.4074 - mean_absolute_error: 3.4074 - val_loss: 3.2533 - val_mean_absolute_error: 3.2533\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.4013 - mean_absolute_error: 3.4013 - val_loss: 3.4060 - val_mean_absolute_error: 3.4060\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3784 - mean_absolute_error: 3.3784 - val_loss: 3.2581 - val_mean_absolute_error: 3.2581\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3457 - mean_absolute_error: 3.3457 - val_loss: 3.2784 - val_mean_absolute_error: 3.2784\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.3261 - mean_absolute_error: 3.3261 - val_loss: 3.2415 - val_mean_absolute_error: 3.2415\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.3070 - mean_absolute_error: 3.3070 - val_loss: 3.2462 - val_mean_absolute_error: 3.2462\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2883 - mean_absolute_error: 3.2883 - val_loss: 3.3362 - val_mean_absolute_error: 3.3362\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.2781 - mean_absolute_error: 3.2781 - val_loss: 3.1457 - val_mean_absolute_error: 3.1457\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.2376 - mean_absolute_error: 3.2376 - val_loss: 3.2768 - val_mean_absolute_error: 3.2768\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2511 - mean_absolute_error: 3.2511 - val_loss: 3.1941 - val_mean_absolute_error: 3.1941\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.2513 - mean_absolute_error: 3.2513 - val_loss: 3.0862 - val_mean_absolute_error: 3.0862\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.2411 - mean_absolute_error: 3.2411 - val_loss: 3.3700 - val_mean_absolute_error: 3.3700\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1937 - mean_absolute_error: 3.1937 - val_loss: 3.1091 - val_mean_absolute_error: 3.1091\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.1680 - mean_absolute_error: 3.1680 - val_loss: 3.2449 - val_mean_absolute_error: 3.2449\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1495 - mean_absolute_error: 3.1495 - val_loss: 3.0776 - val_mean_absolute_error: 3.0776\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.1186 - mean_absolute_error: 3.1186 - val_loss: 3.2568 - val_mean_absolute_error: 3.2568\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.1070 - mean_absolute_error: 3.1070 - val_loss: 3.1344 - val_mean_absolute_error: 3.1344\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0894 - mean_absolute_error: 3.0894 - val_loss: 3.1376 - val_mean_absolute_error: 3.1376\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3.0684 - mean_absolute_error: 3.0684 - val_loss: 3.1853 - val_mean_absolute_error: 3.1853\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0843 - mean_absolute_error: 3.0843 - val_loss: 3.1078 - val_mean_absolute_error: 3.1078\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3.0447 - mean_absolute_error: 3.0447 - val_loss: 3.0405 - val_mean_absolute_error: 3.0405\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0689 - mean_absolute_error: 3.0689 - val_loss: 3.2175 - val_mean_absolute_error: 3.2175\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0262 - mean_absolute_error: 3.0262 - val_loss: 3.0566 - val_mean_absolute_error: 3.0566\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0038 - mean_absolute_error: 3.0038 - val_loss: 3.1651 - val_mean_absolute_error: 3.1651\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.0173 - mean_absolute_error: 3.0173 - val_loss: 3.1127 - val_mean_absolute_error: 3.1127\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.9928 - mean_absolute_error: 2.9928 - val_loss: 3.0892 - val_mean_absolute_error: 3.0892\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.9948 - mean_absolute_error: 2.9948 - val_loss: 3.1252 - val_mean_absolute_error: 3.1252\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.9567 - mean_absolute_error: 2.9567 - val_loss: 3.0715 - val_mean_absolute_error: 3.0715\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.9675 - mean_absolute_error: 2.9675 - val_loss: 3.1558 - val_mean_absolute_error: 3.1558\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.9372 - mean_absolute_error: 2.9372 - val_loss: 3.0936 - val_mean_absolute_error: 3.0936\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.9155 - mean_absolute_error: 2.9155 - val_loss: 3.1070 - val_mean_absolute_error: 3.1070\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.9046 - mean_absolute_error: 2.9046 - val_loss: 3.1492 - val_mean_absolute_error: 3.1492\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 2.9106 - mean_absolute_error: 2.9106 - val_loss: 3.0940 - val_mean_absolute_error: 3.0940\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.8744 - mean_absolute_error: 2.8744 - val_loss: 3.1222 - val_mean_absolute_error: 3.1222\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.8727 - mean_absolute_error: 2.8727 - val_loss: 3.1259 - val_mean_absolute_error: 3.1259\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.8447 - mean_absolute_error: 2.8447 - val_loss: 3.0458 - val_mean_absolute_error: 3.0458\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.8349 - mean_absolute_error: 2.8349 - val_loss: 3.1718 - val_mean_absolute_error: 3.1718\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.8454 - mean_absolute_error: 2.8454 - val_loss: 3.0416 - val_mean_absolute_error: 3.0416\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.8366 - mean_absolute_error: 2.8366 - val_loss: 3.0816 - val_mean_absolute_error: 3.0816\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.8286 - mean_absolute_error: 2.8286 - val_loss: 3.1911 - val_mean_absolute_error: 3.1911\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.8182 - mean_absolute_error: 2.8182 - val_loss: 3.0852 - val_mean_absolute_error: 3.0852\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.7846 - mean_absolute_error: 2.7846 - val_loss: 3.0974 - val_mean_absolute_error: 3.0974\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.7692 - mean_absolute_error: 2.7692 - val_loss: 3.0264 - val_mean_absolute_error: 3.0264\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.7630 - mean_absolute_error: 2.7630 - val_loss: 3.0699 - val_mean_absolute_error: 3.0699\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.7530 - mean_absolute_error: 2.7530 - val_loss: 3.2058 - val_mean_absolute_error: 3.2058\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.7693 - mean_absolute_error: 2.7693 - val_loss: 3.0647 - val_mean_absolute_error: 3.0647\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.7153 - mean_absolute_error: 2.7153 - val_loss: 3.1899 - val_mean_absolute_error: 3.1899\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.6853 - mean_absolute_error: 2.6853 - val_loss: 3.0501 - val_mean_absolute_error: 3.0501\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.7215 - mean_absolute_error: 2.7215 - val_loss: 3.0979 - val_mean_absolute_error: 3.0979\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 2.6728 - mean_absolute_error: 2.6728 - val_loss: 3.1582 - val_mean_absolute_error: 3.1582\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.6696 - mean_absolute_error: 2.6696 - val_loss: 3.0988 - val_mean_absolute_error: 3.0988\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.6548 - mean_absolute_error: 2.6548 - val_loss: 3.1263 - val_mean_absolute_error: 3.1263\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.6405 - mean_absolute_error: 2.6405 - val_loss: 3.1183 - val_mean_absolute_error: 3.1183\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.6351 - mean_absolute_error: 2.6351 - val_loss: 3.1491 - val_mean_absolute_error: 3.1491\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.5941 - mean_absolute_error: 2.5941 - val_loss: 3.0970 - val_mean_absolute_error: 3.0970\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 2.6028 - mean_absolute_error: 2.6028 - val_loss: 3.1311 - val_mean_absolute_error: 3.1311\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.5827 - mean_absolute_error: 2.5827 - val_loss: 3.1928 - val_mean_absolute_error: 3.1928\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2.5802 - mean_absolute_error: 2.5802 - val_loss: 3.1527 - val_mean_absolute_error: 3.1527\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.5898 - mean_absolute_error: 2.5898 - val_loss: 3.0988 - val_mean_absolute_error: 3.0988\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2.6046 - mean_absolute_error: 2.6046 - val_loss: 3.2437 - val_mean_absolute_error: 3.2437\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.6023 - mean_absolute_error: 2.6023 - val_loss: 3.0935 - val_mean_absolute_error: 3.0935\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.5126 - mean_absolute_error: 2.5126 - val_loss: 3.2199 - val_mean_absolute_error: 3.2199\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.5633 - mean_absolute_error: 2.5633 - val_loss: 3.1661 - val_mean_absolute_error: 3.1661\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.6106 - mean_absolute_error: 2.6106 - val_loss: 3.1385 - val_mean_absolute_error: 3.1385\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.5033 - mean_absolute_error: 2.5033 - val_loss: 3.2575 - val_mean_absolute_error: 3.2575\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.4829 - mean_absolute_error: 2.4829 - val_loss: 3.2291 - val_mean_absolute_error: 3.2291\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.4699 - mean_absolute_error: 2.4699 - val_loss: 3.2254 - val_mean_absolute_error: 3.2254\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.4532 - mean_absolute_error: 2.4532 - val_loss: 3.1407 - val_mean_absolute_error: 3.1407\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.4415 - mean_absolute_error: 2.4415 - val_loss: 3.1487 - val_mean_absolute_error: 3.1487\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.4078 - mean_absolute_error: 2.4078 - val_loss: 3.3089 - val_mean_absolute_error: 3.3089\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.4254 - mean_absolute_error: 2.4254 - val_loss: 3.1500 - val_mean_absolute_error: 3.1500\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.3861 - mean_absolute_error: 2.3861 - val_loss: 3.2195 - val_mean_absolute_error: 3.2195\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.3782 - mean_absolute_error: 2.3782 - val_loss: 3.2640 - val_mean_absolute_error: 3.2640\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.3645 - mean_absolute_error: 2.3645 - val_loss: 3.3049 - val_mean_absolute_error: 3.3049\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.3243 - mean_absolute_error: 2.3243 - val_loss: 3.1664 - val_mean_absolute_error: 3.1664\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.3206 - mean_absolute_error: 2.3206 - val_loss: 3.2854 - val_mean_absolute_error: 3.2854\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.3080 - mean_absolute_error: 2.3080 - val_loss: 3.2199 - val_mean_absolute_error: 3.2199\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 2.2921 - mean_absolute_error: 2.2921 - val_loss: 3.2283 - val_mean_absolute_error: 3.2283\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.2816 - mean_absolute_error: 2.2816 - val_loss: 3.2492 - val_mean_absolute_error: 3.2492\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.2707 - mean_absolute_error: 2.2707 - val_loss: 3.3696 - val_mean_absolute_error: 3.3696\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.2581 - mean_absolute_error: 2.2581 - val_loss: 3.2125 - val_mean_absolute_error: 3.2125\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 2.2259 - mean_absolute_error: 2.2259 - val_loss: 3.1504 - val_mean_absolute_error: 3.1504\n"
     ]
    }
   ],
   "source": [
    "history = fc_model.fit(\n",
    "    train_features, train_G3_targets,\n",
    "    validation_split=0.2,\n",
    "    verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline mean absolute error: 3.3839049339294434\n",
      "Saved baseline model to: C:\\Users\\z0042fkb\\AppData\\Local\\Temp\\tmpt7_s684m.h5\n"
     ]
    }
   ],
   "source": [
    "test_results = {}\n",
    "_, test_results['fc_model'] = fc_model.evaluate(test_features, test_G3_targets, verbose=0)\n",
    "\n",
    "print('Baseline mean absolute error:', test_results['fc_model'])\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(fc_model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\z0042fkb\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_wrapper.py:200: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set.\n",
    "\n",
    "num_features = train_features.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_features / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(fc_model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_dense_8  (None, 32)                2914      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_9  (None, 16)                1042      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_10 (None, 8)                 266       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_11 (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 4,241\n",
      "Trainable params: 2,145\n",
      "Non-trainable params: 2,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='mean_absolute_error',\n",
    "              metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 4.4794 - mean_absolute_error: 4.4794WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "2/9 [=====>........................] - ETA: 0s - loss: 3.8298 - mean_absolute_error: 3.8298WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0057s vs `on_train_batch_end` time: 0.2242s). Check your callbacks.\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 2.9520 - mean_absolute_error: 2.9520 - val_loss: 3.2266 - val_mean_absolute_error: 3.2266\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 2.8601 - mean_absolute_error: 2.8601 - val_loss: 3.2534 - val_mean_absolute_error: 3.2534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22d2c9bdeb8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and evaluate the model against baseline\n",
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_features, train_G3_targets,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step - loss: 3.2778 - mean_absolute_error: 3.2778\n",
      "Baseline mean absolute error: 3.3839049339294434\n",
      "Pruned mean absolute error: 3.277818441390991\n",
      "Saved baseline model to: C:\\Users\\z0042fkb\\AppData\\Local\\Temp\\tmpn6odn1lf.h5\n"
     ]
    }
   ],
   "source": [
    "_, test_results['pruned_model'] = model_for_pruning.evaluate(\n",
    "   test_features, test_G3_targets, verbose=1)\n",
    "\n",
    "print('Baseline mean absolute error:', test_results['fc_model']) \n",
    "print('Pruned mean absolute error:', test_results['pruned_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: C:\\Users\\z0042fkb\\AppData\\Local\\Temp\\tmphundugai.h5\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\z0042fkb\\AppData\\Local\\Temp\\tmp3lfhfjqm\\assets\n",
      "Saved pruned TFLite model to: C:\\Users\\z0042fkb\\AppData\\Local\\Temp\\tmp4f__pefl.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of gzipped baseline Keras model: 9866.00 bytes\n",
      "Size of gzipped pruned Keras model: 6795.00 bytes\n",
      "Size of gzipped pruned TFlite model: 6005.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
